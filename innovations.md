

<http://www.emergtoplifesci.org/>
<pre>

Therefore, I wanted to get in touch as we are putting together an
issue of our interdisciplinary journal, Emerging Topics in Life
Sciences <http://www.emergtoplifesci.org/>, on the scholarly publishing
landscape, with the focus being on the current impact on and
implications for life science researchers. The issue would cover a
number of aspects of the scholarly publishing landscape, including
research data, open science, persistent identifiers, models of peer
review, research ethics, and we would like to cover the view from a
life science researcher. In particular, thinking about the following
questions:


*         What does the scholarly publishing landscape look like in
          2018 (from a life scientists perspective)?

*         What are the considerations, regulations and expectations
          from the perspective of a life science researcher, and what
          do the pros and cons of compliance look like to them?

*         How are emerging topics in scholarly publishing improving or holding back the science?

Would you be interested in writing a short perspective piece on
emerging topics in scholarly publishing and the impact and implication
for the life science researcher? We are asking for short
(approx. 1000-1500 words) pieces. Given that this issue needs to be
published before the end of the year, we would need submission of the
piece in the next few weeks (1 November deadline).  </pre>



# Scholarly publishing in the life sciences: the life scientists' perspective.

Stephen J Eglen [orcid](https://orcid.org/0000-0001-8607-8025),
Ross Mounce [orcid](https://orcid.org/0000-0002-3520-2046|).

**(add your name and orcid here)**

# Introduction

In some ways, the state of scholarly publishing has not changed much
in the last ten years.  Publishing in a top-tier journal is still
perceived as critical for career progression (promotion, gaining
grants) by scientists.  Likewise, journal metrics continue to dominate
in the evalution of a paper's research, rather than reading the paper
itself [Brenner].  However, there are several reasons for optimism
that the nature of scientific publishing will improve.  Here we
outline some recent deveopments in the life sciences.

## Preprints

Since 1991 physicists have heralded the preprint server ArXiv
[Ginsparg 2017] as a rapid way of disseminating their research
findings.  On the surface, it does not provide much beyond a
collection of PDFs grouped by topic.  In certain fields, being the
first to publish on the ArXiv is considered to be the key step,
although subsequent journal publication is still the norm.  Although
ArXiv hosts papers in quantitative biology, it was assumed that
biologists would not adopt a preprint culture: publishing a preprint
might prevent subsequent publication in a top-tier journal, or leading
to scooping by another group.

BiorXiv, launched in 2013, has overcome these concerns. Researchers in
diverse areas as ecology, neuroscience, genomics are uploading
preprints and choosing to share their work ahead of publication.
There are many reasons for this usage:

* Sharing work before submitting to a journal allows for community
  feedback.
* Sharing work at the time of submission means that the community can
  read the work months (or years) before the work eventually
  appears in print.
* Journal editors are browsing the bioRxiv and soliciting that
  relevant papers be submitted to their journal.  (How widespread this
  is, I'm not sure.)
* BioRxiv preprints can be transferred rapidly to journal submission
  sytems rather than going through (often lengthy) direct submission
  to the journal.
* Several funding agencies, including NIH and UKRI, allows
  preprints to be listed and cited in grant applications.


Several other preprint servers have been created in recent year, in
particular [PeerJ Preprints](https://peerj.com/preprints/), [OSF
Preprint servers](https://osf.io/preprints/), and
[preprints.org](https://preprints.org), although to date BioRxiv is
the dominant repository.  Unlike a few years ago, very few journals in
the life sciences now regard a preprint as prior publication of that
work.

## Preregistration studies

According to recent surveys, life scientists across many domains
believe there is a "reproducibility crisis" in science: i.e. key
findings of a paper have not been independently verified [REF].  An
encouraging response to this crisis has been the adoption of
preregistratation papers [Nosek 2018].  These papers typically
describe the introduction and methods sections of a paper, and are
peer-reviewed *before* the study is actually performed.  This allows
reviewers to improve the study design and commits researchers to
hypotheses that they wish to study along with their statistical
analysis.  Once the pre-registration study is approved, it is then
published.  After the research is completed, another paper describes
the results of the study using the pre-registered methods.
(Additional findings can be reported, but are clearly marked as such.)
Preregistration is most prevalent today in psychology. The Center for
Open Science Preregistration Challenge https://cos.io/prereg/ is
helping to popularise this notion more broadly.


## Other recent innovations of note


ORCiD <https://orcid.org> provides a persistent, unique digital identifier for
researchers.  Many journals now require that at least one author
verifies their identity as author using ORCiD
[https://orcid.org/content/requiring-orcid-publication-workflows-open-letter].

**DORA** https://sfdora.org/ is a declaration for individiauls and
institutions to commit to evaluating research based on its content
rather than metrics.  Most UK funders have signed, although only a few
Universites have signed. See also the Leiden Manifesto for Research
Metrics (http://www.leidenmanifesto.org/).

**Published Peer Review Reports**.

Many journals now already or have pledged to provide greater
transparency about the quality of peer review they provide by
publishing the content of the reviewer reports alongside published
articles. Notably two large open access publishers PLOS and MDPI are
amongst those that are pledging to provide greater transparency from
2019 http://asapbio.org/letter.  PubPeer <https://pubpeer.com/>
allows reviewers to 'claim' metadata records on their profile for peer
reviewing and editorial work they have done.

**Post publication peer review**.  A journal may immediately publish a
paper upon submission; reviews are then sought for the preprint and
made public.  If sufficient reviewers support publication, the
article is formally accepted and e.g. listed on pubmed.  Leading examples of
this approach are F1000 Research, who provide the infrastructure for
several institution- and funder-specific journals, such as *Wellcome
Open Research* and *Gates Open Research*.

**Format free submissions**.  Journals have traditionally imposed
strict formatting requirements for manuscripts before peer review.
As editors at top-tier journals 'desk reject' most submissions before
peer review, this leads to many wasted hours [Budd 2017].  Gradually
life science journals are now dropping these formatting requirements
for initial submissions, instead allowing "format free" submissions 
[Khan 2017; see  also https://asntech.github.io/format-free-journals/].

**Stronger data sharing policies and community expectations** Both
funders and journals are now making stronger statements about what
research materials (data, computer programs, reagents) should be
shared upon publication of the corresponding articles.  Although these
policies should increase data availability and reuse, the current
compliance rates are quite low [Federer et al 2018].  Given that it
can take considerable time and effort (for both researchers and
journals) to ensure data is appropriately shared, these low-uptake
rates are perhaps expected.  To reward authors for this work, "data
papers" (a paper  that simply describes the data) are becoming more
prominent, e.g. in journals like *Scientific Data* and *Gigascience*.






## Funder mandates and compliance

Key Funders in the UK have had policies in place supporting open
access for many years.  IN particular, the Wellcome Trust has mandated
Open Access for publications funded by them since 2006, with sanctions
for non-compliance.  Compliance rates (around 90%) are highest for the
WT, as of October 2017 [Larivière and Sugimoto 2018], with compliance
for other main funders varying at 70-90%.  Where work has been
supported by relevant funding agencies, our experience to date is that
funds have always been available to support APCs.  However, one of us
[SJE] has experienced difficulties in finding APCs for papers
summarising work supported by internal, rather than external, funds.


One perhaps unintended consequence of these policies has been that
most traditional journals have established a "hybrid" model of
publishing, with APCs that on average exceed those in pure OA journals
[Pinfield et al 2017].  This hybrid model of publishing has shown
little signs to date of disappearing, as e.g. funds from Wellcome
Trust have supported high APCs. The success of OA publishing however
has meant that goverment-provided funds can often no longer cover all
APCs and UK institutions are beginning to restrict the choice of
journals for which APCs will be paid.  However, The OA publishing
world is due to change dramatically in 2020 with the recent
announcement of "plan S" [Schiltz 2018], a European initiative to
enforce OA, cap APCs and prohibit publishing in hybrid journals.
Whilst we support the notions underlying plan S, until further details
are released (e.g. the nature of the APC cap, recognition of green and
diamond OA).



# Concluding remarks

We have outlined several recent developments that we hope present
alternatives to the traditional hierarchy of scholarly publishing.
These develpments should help reduce the pressure on early career
researchers that they currently face in the "publish or perish"
culture.  To recognise this pressure, we have created an initiative
called *Bullied into Bad Science* (http://bulliedintobadscience.org/).
We encourage the adoption of the above open practices to help create a
more ethical research environment.







overlay journals?


# Glossary/abbreviations


Perhaps need a list of key abbreviations/terms that are jargon
(APCs/hybrid/diamond OA).

# References

Khan A, Montenegro-Montero A, Mathelier A (2018) Put science first and
formatting later. EMBO Rep 19 Available at:
http://dx.doi.org/10.15252/embr.201845731.

Budd J (2017) Publishing: Reformatting wastes public funds. Nature
543:40 Available at: http://dx.doi.org/10.1038/543040e.

Else H (2018) Radical open-access plan could spell end to journal
subscriptions. Nature 561:17–18 Available at:
http://dx.doi.org/10.1038/d41586-018-06178-7.

Federer LM, Belter CW, Joubert DJ, Livinski A, Lu Y-L, Snyders LN,
Thompson H (2018) Data sharing in PLOS ONE: An analysis of Data
Availability Statements. PLoS One 13:e0194768 Available at:
http://dx.doi.org/10.1371/journal.pone.0194768.

Nosek BA, Ebersole CR, DeHaven AC, Mellor DT (2018) The
preregistration revolution. Proc Natl Acad Sci U S A 115:2600–2606
Available at: http://dx.doi.org/10.1073/pnas.1708274114.

Larivière V, Sugimoto CR (2018) Do authors comply when funders enforce
open access to research? Nature 562:483 Available at:
https://www.nature.com/articles/d41586-018-07101-w [Accessed October
25, 2018].

Ginsparg P (2017) Preprint Déjà Vu: an FAQ. arXiv [csDL] Available at:
https://arxiv.org/abs/1706.04188.

Anon (2017) Are preprints the future of biology? A survival guide for
scientists. Science | AAAS Available at:
https://www.sciencemag.org/news/2017/09/are-preprints-future-biology-survival-guide-scientists
[Accessed October 26, 2018].



# notes (not for paper)

removed text about overlay journal...
BioRxiv can even be used as the substrate for an overlay journal
(example?), and we look forward to the creation of prominent diamond
OA overlay journals in the life sciences.

**Badges** to promote sharing of resources, rather than just the
papers.  e.g. mention data papers?  (Not sure whether to include
this.) (Ross: I'm not that enthused about badges https://blogs.plos.org/absolutely-maybe/2017/08/29/bias-in-open-science-advocacy-the-case-of-article-badges-for-data-sharing/ )

ORCID This will undoubtedly help reduce many types of authorship fraud (cite http://nautil.us/issue/42/fakes/why-fake-data-when-you-can-fake-a-scientist ?)  

Crossref can now register DOIs for peer
review reports as a distinct content type, and formally link these to
the DOIs of the articles they review
(https://www.crossref.org/news/2018-06-05-introducing-metadata-for-peer-review/).

Nice figure for preprint usage at: http://www.prepubmed.org/monthly_stats/
