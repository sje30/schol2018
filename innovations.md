<http://www.emergtoplifesci.org/>
<pre>

Therefore, I wanted to get in touch as we are putting together an
issue of our interdisciplinary journal, Emerging Topics in Life
Sciences <http://www.emergtoplifesci.org/>, on the scholarly publishing
landscape, with the focus being on the current impact on and
implications for life science researchers. The issue would cover a
number of aspects of the scholarly publishing landscape, including
research data, open science, persistent identifiers, models of peer
review, research ethics, and we would like to cover the view from a
life science researcher. In particular, thinking about the following
questions:


*         What does the scholarly publishing landscape look like in
	  2018 (from a life scientists perspective)?

*         What are the considerations, regulations and expectations
	  from the perspective of a life science researcher, and what
	  do the pros and cons of compliance look like to them?

*         How are emerging topics in scholarly publishing improving or holding back the science?

Would you be interested in writing a short perspective piece on
emerging topics in scholarly publishing and the impact and implication
for the life science researcher? We are asking for short
(approx. 1000-1500 words) pieces. Given that this issue needs to be
published before the end of the year, we would need submission of the
piece in the next few weeks (1 November deadline).  </pre>



# Scholarly publishing in the life sciences: the life scientists' perspective.

Stephen J Eglen [orcid](https://orcid.org/0000-0001-8607-8025),
Ross Mounce [orcid](https://orcid.org/0000-0002-3520-2046),
Laurent Gatto [orcid](https://orcid.org/0000-0002-1520-2268).

**(add your name and orcid here)**

# Introduction


In some ways, scholarly publishing has not changed much in the last
ten years. Publishing in prestigious top-tier journals is still
perceived as critical for career progression (especially gaining
promotion and grants). Likewise, journal metrics continue to dominate
in the evalution of a paper’s research, rather than the paper’s
contents [Brenner]. Against the backdrop of highly competitive job and
grant markets, factors such as these encourage narrow research agendas
and tie researchers (particularly in early career) to placing work in
exploitative publishers who draw significant funds from academic
work. Further, standard publishing criteria, especially for instance on
publishing statistically significant, positive results, creates biases
across published studies. However, there are several reasons for
optimism that the nature of scientific publishing will improve. Here
we outline some recent deveopments in the life sciences.



## Preprints

Since 1991 ArXiv [Ginsparg 2017] has become a standard tool for
physicists to rapidly disseminate their research findings.  On the
surface, it does not provide much beyond a collection of PDFs grouped
by topic.  In certain fields, being the first to publish on the ArXiv
is considered to be the key step, although subsequent journal
publication is still the norm.  Although ArXiv hosts papers in
quantitative biology, it was initially assumed that biologists would
not adopt a preprint culture: publishing a preprint might prevent
subsequent publication in a top-tier journal, or leading to scooping
by another group.

BiorXiv, launched in 2013, has overcome these concerns. Researchers in
diverse areas as ecology, neuroscience and genomics are uploading
preprints and choosing to share their work ahead of publication.
There are many reasons for this usage:

* Sharing work before submitting to a journal allows for community
  feedback.
* Sharing work at the time of submission means that the community can
  read the work months (or years) before the work eventually
  appears in print.
* Journal editors are browsing the bioRxiv and soliciting that
  relevant papers be submitted to their journal.  (How widespread this
  is, I'm not sure.)
* BioRxiv preprints can be transferred rapidly to journal submission
  systems rather than going through (often lengthy) direct submission
  to the journal.
* Several funding agencies, including NIH and UKRI, allows
  preprints to be listed and cited in grant applications.


Several other preprint servers have been created in recent year, in
particular [PeerJ Preprints](https://peerj.com/preprints/), [OSF
Preprint servers](https://osf.io/preprints/), and
[preprints.org](https://preprints.org), although to date BioRxiv is
the dominant repository.  Unlike a few years ago, most journals in the
life sciences no longer see prior appearance in a repository as a
block to formal publication.

## Overcoming the reproducibility crisis

According to recent surveys, life scientists across many domains
believe there is a "reproducibility crisis" in science: i.e. many key
key findings in publications are either not independently verified, or
fail verification when it is done [REF].  The traditional publishing
system must take some responsibility for these low-levels of
reproducibility.  However, here we list three encouraging developments
that should promote reproducbility.

**Preregistration papers.** An encouraging response to this crisis has
been the adoption of preregistratation papers [Nosek 2018].  These
papers typically describe the introduction and methods sections of a
paper, and are peer-reviewed *before* the study is actually performed.
This allows reviewers to improve the study design and commits
researchers to hypotheses that they wish to study along with their
statistical analysis.  Once the pre-registration study is approved, it
is then published.  After the research is completed, another paper
describes the results of the study using the pre-registered methods.
(Additional findings can be reported, but are clearly marked as such.)
Preregistration is most prevalent today in psychology; The Center for
Open Science Preregistration Challenge https://cos.io/prereg/ is
helping to popularise this notion more broadly.

**Stronger data sharing policies and community expectations.** Both
funders and journals are now making stronger statements about what
research materials (data, computer programs, reagents) should be
shared upon publication of the corresponding articles.  Although these
policies should increase data availability and reuse, the current
compliance rates are quite low [Federer et al 2018].  Given that it
can take considerable time and effort (for both researchers and
journals) to ensure data is appropriately shared, these low-uptake
rates are perhaps expected.  To reward authors for this work, "data
papers" (a paper  that simply describes the data) are becoming more
prominent, e.g. in journals like *Scientific Data* and *Gigascience*.

**Reproducible manuscripts**  are documents that contain the main text
as well as the code to generate tables, figures and results have
been around for decades, and have been widely used in many
research fields. However, even though researchers have been
committed to reproducible research, the reproducibility of the
final outputs were generally broken upon submission to
journals. Recently, some journals have published fully
reproducible manuscripts. Examples (need to get the links) are
eLife, F1000Research, ... (other examples?).

## Other recent innovations of note


**ORCiD** <https://orcid.org> provides a persistent, unique digital identifier for
researchers.  Many journals now require that at least one author
verifies their identity as author using ORCiD
[https://orcid.org/content/requiring-orcid-publication-workflows-open-letter].

**DORA** https://sfdora.org/ is a declaration for individuals and
institutions to commit to evaluating research based on its content
rather than metrics.  Most UK funders have signed, although only a few
Universites have signed. See also the Leiden Manifesto for Research
Metrics (http://www.leidenmanifesto.org/).

**Published Peer Review Reports**.  Many journals now already or have
pledged to provide greater transparency about the quality of peer
review they provide by publishing the content of the reviewer reports
alongside published articles. Notably two large open access publishers
PLOS and MDPI are amongst those that are pledging to provide greater
transparency from 2019 http://asapbio.org/letter.  PubPeer
<https://pubpeer.com/> allows reviewers to 'claim' metadata records on
their profile for peer reviewing and editorial work they have done.

**Post publication peer review**.  A journal may immediately publish a
paper upon submission; reviews are then sought for the preprint and
made public.  If sufficient reviewers support publication, the
article is formally accepted and e.g. listed on pubmed.  Leading examples of
this approach are F1000 Research, who provide the infrastructure for
several institution- and funder-specific journals, such as *Wellcome
Open Research* and *Gates Open Research*.

**Format free submissions**.  Journals have traditionally imposed
strict formatting requirements for manuscripts before peer review.
As editors at top-tier journals 'desk reject' most submissions before
peer review, this leads to many wasted hours [Budd 2017].  Gradually
life science journals are now dropping these formatting requirements
for initial submissions, instead allowing "format free" submissions
[Khan 2017; see  also https://asntech.github.io/format-free-journals/].







## Funder mandates and compliance

Key Funders in the UK have had policies in place supporting open
access for many years.  In particular, the Wellcome Trust has mandated
Open Access for publications funded by them since 2006, with sanctions
for non-compliance.  Compliance rates (around 90%) are highest for the
WT, as of October 2017 [Larivière and Sugimoto 2018], with compliance
for other main funders varying at 70-90%.  Where work has been
supported by relevant funding agencies, our experience to date is that
funds have always been available to support APCs.  However, one of us
[SJE] has experienced difficulties in finding APCs for papers
summarising work supported by internal, rather than external, funds.


One perhaps unintended consequence of these policies has been that
most traditional journals have established a "hybrid" model of
publishing, with APCs that on average exceed those in pure OA journals
[Pinfield et al 2017].  This hybrid model of publishing has shown
little signs to date of disappearing, as e.g. funds from Wellcome
Trust have supported high APCs. The success of OA publishing however
has meant that goverment-provided funds can often no longer cover all
APCs and UK institutions are beginning to restrict the choice of
journals for which APCs will be paid.  However, The OA publishing
world is due to change dramatically in 2020 with the recent
announcement of "plan S" [Schiltz 2018], a European initiative to
enforce OA, cap APCs and prohibit publishing in hybrid journals.
Whilst we support the notions underlying plan S, until further details
are released (e.g. the nature of the APC cap, recognition of green and
diamond OA).



# Concluding remarks

Current publication practices can often lead early career researchers
to be ‘Bullied into Bad Science’ (http://bulliedintobadscience.org/).
We have outlined several recent developments that we hope present
alternatives to the traditional hierarchy of scholarly publishing.
These develpments should help reduce the pressure on early career
researchers that they currently face in the "publish or perish"
culture.  We encourage the adoption of the above open practices to
help create a more ethical research environment.







overlay journals?


# Glossary/abbreviations


Perhaps need a list of key abbreviations/terms that are jargon
(APCs/hybrid/diamond OA).

# References

Khan A, Montenegro-Montero A, Mathelier A (2018) Put science first and
formatting later. EMBO Rep 19 Available at:
http://dx.doi.org/10.15252/embr.201845731.

Budd J (2017) Publishing: Reformatting wastes public funds. Nature
543:40 Available at: http://dx.doi.org/10.1038/543040e.

Else H (2018) Radical open-access plan could spell end to journal
subscriptions. Nature 561:17–18 Available at:
http://dx.doi.org/10.1038/d41586-018-06178-7.

Federer LM, Belter CW, Joubert DJ, Livinski A, Lu Y-L, Snyders LN,
Thompson H (2018) Data sharing in PLOS ONE: An analysis of Data
Availability Statements. PLoS One 13:e0194768 Available at:
http://dx.doi.org/10.1371/journal.pone.0194768.

Nosek BA, Ebersole CR, DeHaven AC, Mellor DT (2018) The
preregistration revolution. Proc Natl Acad Sci U S A 115:2600–2606
Available at: http://dx.doi.org/10.1073/pnas.1708274114.

Larivière V, Sugimoto CR (2018) Do authors comply when funders enforce
open access to research? Nature 562:483 Available at:
https://www.nature.com/articles/d41586-018-07101-w [Accessed October
25, 2018].

Ginsparg P (2017) Preprint Déjà Vu: an FAQ. arXiv [csDL] Available at:
https://arxiv.org/abs/1706.04188.

Anon (2017) Are preprints the future of biology? A survival guide for
scientists. Science | AAAS Available at:
https://www.sciencemag.org/news/2017/09/are-preprints-future-biology-survival-guide-scientists
[Accessed October 26, 2018].



# notes (not for paper)

removed text about overlay journal...
BioRxiv can even be used as the substrate for an overlay journal
(example?), and we look forward to the creation of prominent diamond
OA overlay journals in the life sciences.

**Badges** to promote sharing of resources, rather than just the
papers.  e.g. mention data papers?  (Not sure whether to include
this.) (Ross: I'm not that enthused about badges https://blogs.plos.org/absolutely-maybe/2017/08/29/bias-in-open-science-advocacy-the-case-of-article-badges-for-data-sharing/ )

ORCID This will undoubtedly help reduce many types of authorship fraud (cite http://nautil.us/issue/42/fakes/why-fake-data-when-you-can-fake-a-scientist ?)

Crossref can now register DOIs for peer
review reports as a distinct content type, and formally link these to
the DOIs of the articles they review
(https://www.crossref.org/news/2018-06-05-introducing-metadata-for-peer-review/).

Nice figure for preprint usage at: http://www.prepubmed.org/monthly_stats/
